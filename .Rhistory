head(data3)
require(ggplot2)
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")+
scale_fill_brewer(palette="Greens")+xlab("")+ylab("")
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")+
coord_polar()+
scale_fill_brewer(palette="Greens")+xlab("")+ylab("")
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity",width=1,colour="black",size=0.1)+
coord_polar()+
scale_fill_brewer(palette="Greens")+
xlab("")+ylab("")
ggplot(data=data3,aes(x=variable,y=group,fill=value))+
geom_tile(colour="black",size=0.1)+
scale_fill_gradientn(colours=c("white","steelblue"))+
coord_polar()+xlab("")+ylab("")
data2
data1
data2
data1
data2=data1[3:8,]
data2
colnames(data2)=month.name
data2$group=row.names(data2)
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[3:8,]
colnames(data2)=month.name
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
data1
data3
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[2:8,]
#colnames(data2)=month.name
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[2:8,]
#colnames(data2)=month.name
#data2$group=row.names(data2)
data3=melt(data2,id="group")
require(reshape2)
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[2:8,]
colnames(data2)=month.name
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
require(ggplot2)
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[3:8,]
colnames(data2)=month.name
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
require(ggplot2)
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")+
scale_fill_brewer(palette="Greens")+xlab("")+ylab("")
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")+
coord_polar()+
scale_fill_brewer(palette="Greens")+xlab("")+ylab("")
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity",width=1,colour="black",size=0.1)+
coord_polar()+
scale_fill_brewer(palette="Greens")+
xlab("")+ylab("")
ggplot(data=data3,aes(x=variable,y=group,fill=value))+
geom_tile(colour="black",size=0.1)+
scale_fill_gradientn(colours=c("white","steelblue"))+
coord_polar()+xlab("")+ylab("")
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[3:8,]
colnames(data2)=month.name
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
require(ggplot2)
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[3:8,]
colnames(data2)=month.name
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
#Regression and residuals values calculations of average size army vs zymotic disease:
cor(data$avg_size_army, data$zymotic)
reg1 <- lm(avg_size_army ~ zymotic, data=data)
summary(reg1)
#Correlation with Newey-West to have into account the autocorrelation
coeftest(reg1, NeweyWest(reg1))
resid1 <- as.numeric(reg1$residuals) #Veig que tu calcules els residus d'una altra manera (comparant-ho amb el bloc de codi on vas fer el QQplot dels residus d'un model). Decidim de quina manera ho deixem
qqnorm(resid1, col="tomato", main="Model 1: Avg Size Army vs. Zymotic")
qqline(resid1, lwd=2, lty=3)
#Regression and residuals values calculations of average size army vs injuries:
cor(data$avg_size_army, data$injuries)
reg2 <- lm(avg_size_army ~ injuries, data=data)
summary(reg2)
coeftest(reg2, NeweyWest(reg2))
resid2 <- as.numeric(reg2$residuals)
qqnorm(resid2, col="tomato", main="Model 2: Avg Size Army vs. Injuries")
qqline(resid2, lwd=2, lty=3)
#Regression and residuals values calculations of average size army vs other disease:
cor(data$avg_size_army, data$other)
reg3 <- lm(avg_size_army ~ other, data=data)
summary(reg3)
coeftest(reg3, NeweyWest(reg3))
resid3 <- as.numeric(reg3$residuals)
qqnorm(resid3, col="tomato", main="Model 3: Avg Size Army vs. Other")
qqline(resid3, lwd=2, lty=3)
#Multivariant linear regresion between all deaths (segregated) and the average size of army:
reg4 <- lm(avg_size_army ~ data$zymotic+data$injuries+data$other, data=data)
summary(reg4)
coeftest(reg4, NeweyWest(reg4))
#Comentem que totes son negatives excepte una. Les morts d'aquesta causa van fer que reclutessin més soldats?
resid4 <- as.numeric(reg4$residuals)
qqnorm(resid4, col="tomato", main="Model 4: Avg Size Army vs. Zymotic, Injuries and Other")
qqline(resid4, lwd=2, lty=3)
cor(data$avg_size_army, data$total_deaths) #Valor absolut entre 0 i 1? Com més properes a 1 en valor absolut més correlacionades estan.
reg5 <- lm(avg_size_army ~ total_deaths, data=data)
summary(reg5)
coeftest(reg5, NeweyWest(reg5))
resid5 <- as.numeric(reg5$residuals)
qqnorm(resid5, col="tomato", main="Model 5: Avg Size Army vs. Total Deaths")
qqline(resid5, lwd=2, lty=3)
cor(data$zymotic, data$time_period)
reg6 <- lm(zymotic ~ time_period, data=data)
summary(reg6)
coeftest(reg6, NeweyWest(reg6))
resid6 <- as.numeric(reg6$residuals)
qqnorm(resid6, col="tomato", main="Model 6: Zymotic vs. Time Period")
qqline(resid6, lwd=2, lty=3)
cor(data$injuries, data$time_period)
reg7 <- lm(injuries ~ time_period, data=data)
summary(reg7)
coeftest(reg7, NeweyWest(reg7))
resid7 <- as.numeric(reg7$residuals)
qqnorm(resid7, col="tomato", main="Model 7: Injuries vs. Time Period")
qqline(resid7, lwd=2, lty=3)
cor(data$other, data$time_period)
reg8 <- lm(other ~ time_period, data=data)
summary(reg8)
coeftest(reg8, NeweyWest(reg8))
resid8 <- as.numeric(reg8$residuals)
qqnorm(resid8, col="tomato", main="Model 8: Other vs. Time Period")
qqline(resid8, lwd=2, lty=3)
reg9 <- lm(total_deaths ~ time_period, data=data)
summary(reg9)
coeftest(reg9, NeweyWest(reg9))
resid9 <- as.numeric(reg9$residuals)
qqnorm(resid9, col="tomato", main="Model 9: Total Deaths vs. Time Period")
qqline(resid9, lwd=2, lty=3)
#Si no fem plot de total_deaths a l'apartat 2 fer-lo aquí juntament amb l'estudi de l'estacionarietat (si no és estacionària no podem aplicar-li un model autoregressiu)
adf.test(data$total_deaths)
# Segons el test és estacionària però tbh mirant el gràfic a mi no m'ho sembla
tra_death <- data.frame(y=data$total_deaths[2:L], lag1=data$total_deaths[1:(L-1)])
cor(tra_death$y, tra_death$lag1)
reg10 <- lm(y ~ lag1, data=tra_death)
summary(reg10)
coeftest(reg10, NeweyWest(reg10))
resid10 <- as.numeric(reg10$residuals)
qqnorm(resid10, col="tomato", main="Model 10: Total Deaths vs. Total Deaths Lagged")
qqline(resid10, lwd=2, lty=3)
#Una altra manera de crear models autoregressius:
acf(data$total_deaths, ylim=c(-0.2,1), lwd=5, xlim=c(0,25), col="darkorange2", main="Autocorrelation function total deaths") #Exponential decay
pacf(data$total_deaths, ylim=c(-0.2,1), lwd=5, xlim=c(0,25), col="darkorange2", main="Parcial autocorrelation function total deaths") #Només hi ha un lag que sigui significatiu
#Pel que ens mostren les funcions d'autocorrelació, el més adequat és un model AR(1)
reg11 <- arima(data$total_deaths, c(1,0,0))
coeftest(reg11)
resid11 <- as.numeric(reg11$residuals)
qqnorm(resid11, col="tomato", main="Model 11: Total Deaths vs. Total Deaths Lagged AR(1)")
qqline(resid11, lwd=2, lty=3)
#Veiem que tant una regressió lineal calculada amb la funció lm() dóna el mateix model que quan apliquem un model AR(1) aplicant la funció arima()
reg3 <- lm(formula=data$avg_size_army~data$injuries, data=data)
summary(reg3)
adf.test(data$total_deaths)
tra_death <- data.frame(y=data$total_deaths[2:L], lag1=data$total_deaths[1:(L-1)])
cor(tra_death$y, tra_death$lag1)
reg10 <- lm(y ~ lag1, data=tra_death)
summary(reg10)
coeftest(reg10, NeweyWest(reg10))
resid10 <- as.numeric(reg10$residuals)
qqnorm(resid10, col="tomato", main="Model 10: Total Deaths vs. Total Deaths Lagged")
qqline(resid10, lwd=2, lty=3)
#Podem posar-lo abaix si vols a regressions.
data_plot_3 <- data.frame(
Time=data$time_period,
Total=data$total_deaths)
dygraph(data_plot_3, main="Total deaths (all causes aggregated)")
#No sé si deixar aquest gràfic aquí o graficar les morts totals a l'apartat 4 mentre expliquem l'estacionarietat de la variable per aplicar un model autoregressiu
# Diagnosi dels models: --> Penso que potser hauriem d'escollir el model que funciona millor/té més correlació i fer-ho sobre aquest!
residual.values <- rstandard(reg1)
adjusted.values <- fitted(reg1)
plot(adjusted.values, residual.values, main="Residual plot reg1 (canviar nom maybe)", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)
#He afegit colors al gràfic, poden ser aquests o es poden canviar. Podríem utilitzar els mateixos colors per tots els plots d'un mateix tipus
# Fer diagnosi del model per totes els models i comentar.
qqnorm(residual.values, col="blue")
qqline(residual.values)
#A la vista del gràfic, no s’observa cap patró especial, de manera que tant la homocedasticitat com la linealitat resulten hipòtesis raonables.
#D’altra banda, el Q_Q plot mostra que les dades no s’ajusten bé a una normal.
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
data_plot_3 <- data.frame(
Time=data$time_period,
Total=data$total_deaths)
dygraph(data_plot_3, main="Total deaths (all causes aggregated)")
rm(list=ls())
#Libraries used across the whole project:     (haurem de revisar quins no fem servir al final i treure'ls)
library(readxl)
library(dplyr)
library(tidyverse)
library(gt)
library(dygraphs)
library(formattable)
library(xts)
library(lmtest)
library(tseries)
library(sandwich)
library(forecast)
library(ResourceSelection)
library(pROC)
library(reshape2)
data_plot_5 <- data.frame(
Time=data$time_period,
Total=data$total_deaths)
#Making everything more readable and column names more manageable:
colnames(data)[1] <- "month"
rm(list=ls())
#Libraries used across the whole project:     (haurem de revisar quins no fem servir al final i treure'ls)
library(readxl)
library(dplyr)
library(tidyverse)
library(gt)
library(dygraphs)
library(formattable)
library(xts)
library(lmtest)
library(tseries)
library(sandwich)
library(forecast)
library(ResourceSelection)
library(pROC)
library(reshape2)
#Importing dataset:
data <- read_excel("../nightingale-competition/datos_florence.xlsx", skip=1)
#Making everything more readable and column names more manageable:
colnames(data)[1] <- "month"
colnames(data)[2] <- "avg_size_army"
colnames(data)[3] <- "zymotic"
colnames(data)[4] <- "injuries"
colnames(data)[5] <- "other"
colnames(data)[6] <- "zymotic_rate"
colnames(data)[7] <- "injuries_rate"
colnames(data)[8] <- "other_rate"
data[17,1] <- "Aug 1855" #We modify this entry as in the original dataset it appeared as Aug_1855.
#Creating a numeric variable to account for time period:
L <- nrow(data)
time_period <- seq(0,(L-1)) #Podríem passar-ho de 1 a L
data$time_period <- time_period
data <- as.data.frame(data)
time_vars <- select(data, month, time_period)
time_vars %>%
gt() %>%
tab_header(title = md("**Time periods**"), subtitle = md("Equivalence between both variables"))
#Després de la taula no queda espai (salt de línia) i el paràgraf següent està massa enganxat a la taula
#Adding new variables to the dataset:
deaths <- vector()
for(i in 1:L){
deaths[i] <- data$zymotic[i] + data$injuries[i] + data$other[i]
}
data$total_deaths <- deaths #Agreggated deaths (all causes) per month
cum_deaths <- vector()
cum_deaths <- cumsum(deaths)
data$cum_deaths <- cum_deaths #Cumulative deaths over time
#Checking outliers:
par(mfrow=c(1,3))
boxplot(data$injuries, col="lightgoldenrod", main="Deaths by injuries")
boxplot(data$zymotic, col="mistyrose", main="Deaths by zymotic disease")
boxplot(data$other, col="powderblue", main="Deaths by other causes")
# For the following model we are interested in total deaths in terms of previous values of the same variable. That is, we want to lag the variable and regress total death on its lags to look for significance. The first step, though, is assess for stationarity of the series.
data_plot_5 <- data.frame(
Time=data$time_period,
Total=data$total_deaths)
dygraph(data_plot_5, main="Total deaths (all causes aggregated)")
#The series depicted does not seem very stationary. Nonetheless, we counduct a Dickey-Fuller test.
adf.test(data$total_deaths)
#The series depicted does not seem very stationary. Nonetheless, we counduct a Dickey-Fuller test.
adf.test(data$total_deaths)
total_deaths_diff <- diff(data$total_deaths)
data$total_deaths_diff <- differences
differences <- diff(data$total_deaths)
data$total_deaths_diff <- differences
differences <- diff(data$total_deaths)
total_deaths_diff <- diff(data$total_deaths)
adf.test(tototal_deaths_diff)
adf.test(total_deaths_diff)
total_deaths_diff2 <- diff(total_deaths_diff)
adf.test(total_deaths_diff2)
acf(total_deaths_diff2, ylim=c(-0.2,1), lwd=5, xlim=c(0,25), col="darkorange2", main="Autocorrelation function total deaths") #Exponential decay
pacf(total_deaths_diff2, ylim=c(-0.2,1), lwd=5, xlim=c(0,15), col="darkorange2", main="Parcial autocorrelation function total deaths") #Només hi ha un lag que sigui significatiu
acf(total_deaths_diff, ylim=c(-0.2,1), lwd=5, xlim=c(0,15), col="darkorange2", main="Autocorrelation function total deaths") #Exponential decay
pacf(total_deaths_diff, ylim=c(-0.2,1), lwd=5, xlim=c(0,15), col="darkorange2", main="Parcial autocorrelation function total deaths") #Només hi ha un lag que sigui significatiu
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
rm(list=ls())
#Libraries used across the whole project:
library(readxl)
library(dplyr)
library(tidyverse)
library(gt)
library(dygraphs)
library(formattable)
library(xts)
library(lmtest)
library(tseries)
library(sandwich)
library(forecast)
library(ResourceSelection)
library(pROC)
library(reshape2)
#Importing dataset:
data <- read_excel("../nightingale-competition/datos_florence.xlsx", skip=1)
#Basic information:
head(data)
#Dimensions of the dataset:
dim(data)
#Variables:
sapply(data, class)
summary(data)
#Making everything more readable and column names more manageable:
colnames(data)[1] <- "month"
colnames(data)[2] <- "avg_size_army"
colnames(data)[3] <- "zymotic"
colnames(data)[4] <- "injuries"
colnames(data)[5] <- "other"
colnames(data)[6] <- "zymotic_rate"
colnames(data)[7] <- "injuries_rate"
colnames(data)[8] <- "other_rate"
#Checking missing values:
colSums(is.na(data))
#Checking outliers:
par(mfrow=c(1,3))
boxplot(data$injuries, col="lightgoldenrod", main="Deaths by injuries")
boxplot(data$zymotic, col="mistyrose", main="Deaths by zymotic disease")
boxplot(data$other, col="powderblue", main="Deaths by other causes")
data[17,1] <- "Aug 1855" #We modify this entry as in the original dataset it appeared as Aug_1855.
#Creating a numeric variable to account for time period:
L <- nrow(data)
time_period <- seq(0,(L-1)) #Changing from 1 to L
data$time_period <- time_period
data <- as.data.frame(data)
time_vars <- select(data, month, time_period)
time_vars %>%
gt() %>%
tab_header(title = md("**Time periods**"), subtitle = md("Equivalence between both variables"))
#Adding new variables to the dataset:
deaths <- vector()
for(i in 1:L){
deaths[i] <- data$zymotic[i] + data$injuries[i] + data$other[i]
}
data$total_deaths <- deaths #Agreggated deaths (all causes) per month
cum_deaths <- vector()
cum_deaths <- cumsum(deaths)
data$cum_deaths <- cum_deaths #Cumulative deaths over time
deaths_evol <- select(data, month, total_deaths, time_period)
ordered_deaths <- deaths_evol %>%
arrange(desc(deaths_evol$total_deaths)) #Months arranged from higher to lower number of deaths
#Visualizing in a colorful data table the changes performed:
table_deaths <- data.frame(
Month = ordered_deaths$month,
TotalDeaths = ordered_deaths$total_deaths,
TimePeriod = ordered_deaths$time_period)
formattable(table_deaths, list(
Month = color_tile("lightblue", "lightpink4"),
TotalDeaths = color_bar("grey")))
#y <- ts(data$avg_size_army, frequency=12)
#ggseasonplot(y) +
#ylab("average_size_army") +
#ggtitle("Seasonal plot: Number of Soldiers per Period")
#Explicació de la research que he fet sobre tests de seasonality a idees.txt. Jo ho deixaria així i au jajajjaja:
par(mfrow=c(2,2))
plot(data$avg_size_army, type="line", main="Average Size Army", xlab="Time", ylab="Average Size Army", col="azure4")
plot(data$zymotic, type="line", main="Zymotic Diseases", xlab="Time", ylab="Zymotic Diseases", col="firebrick4")
plot(data$injuries, type="line", main="Injuries", xlab="Time", ylab="Injuries", col="gold4")
plot(data$other, type="line", main="Other Causes", xlab="Time", ylab="Other Causes", col="cyan4")
par(mfrow=c(2,2))
plot(data$avg_size_army, type="line", main="Average Size Army", xlab="Time", ylab="Average Size Army", col="azure4")
plot(data$zymotic, type="line", main="Zymotic Diseases", xlab="Time", ylab="Zymotic Diseases", col="firebrick4")
plot(data$injuries, type="line", main="Injuries", xlab="Time", ylab="Injuries", col="gold4")
plot(data$other, type="line", main="Other Causes", xlab="Time", ylab="Other Causes", col="cyan4")
#How did the different type of deaths measured in absolute values evolve in time?
data_plot_1 <- data.frame(
Time=data$time_period,
Zymotic=data$zymotic,
Injuries=data$injuries,
Other=data$other)
dygraph(data_plot_1, main="Death causes (absolute values)")
#How did the different type of deaths measured in rate values evolve in time?
data_plot_2 <- data.frame(
Time=data$time_period,
Zymotic=data$zymotic_rate,
Injuries=data$injuries_rate,
Other=data$other_rate)
dygraph(data_plot_2, main="Death causes (rates)")
#How did the size of the army evolve in time?
data_plot_3 <- data.frame(
Time=data$time_period,
Army=data$avg_size_army)
dygraph(data_plot_3, main="Average size of the army")
#How did the accumulated number of deaths evolve in time?
data_plot_4 <- data.frame(
Time=data$time_period,
Accumulated_deaths=cum_deaths)
dygraph(data_plot_4, main="Accumulated number of deaths")
#We display the data that is more suitable for the graphs:
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[3:5,]
colnames(data2)=month.abb
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
#Bar graph:
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")+
scale_fill_brewer(palette="RdBu")+xlab("")+ylab("")
#Coordenades polar graph:
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
geom_bar(stat="identity")+
coord_polar()+
scale_fill_brewer(palette="BuPu")+xlab("")+ylab("")
#Heatmap graph:
ggplot(data=data3,aes(x=variable,y=group,fill=value))+
geom_tile(colour="black",size=0.1)+
scale_fill_gradientn(colours=c("white","deepskyblue3"))+
coord_polar()+xlab("")+ylab("")
#Regression and residuals values calculations of average size army vs zymotic disease:
cor(data$avg_size_army, data$zymotic)
reg1 <- lm(avg_size_army ~ zymotic, data=data)
coeftest(reg1, NeweyWest(reg1))
#HAC heteroskedasticity autocorrelation robust std errors
#Correlation with Newey-West to have into account the autocorrelation:
#Residuals calculation:
resid1 <- as.numeric(reg1$residuals)
adjusted.values1 <- fitted(reg1)
plot(adjusted.values1, resid1, main="Residual plot Model 1", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)
qqnorm(resid1, col="tomato", main="Quantile-Comparison Plot Model 1")
qqline(resid1, lwd=2, lty=3)
shapiro.test(resid1)
#Regression and residuals values calculations of average size army vs injuries:
cor(data$avg_size_army, data$injuries)
reg2 <- lm(avg_size_army ~ injuries, data=data)
summary(reg2)
coeftest(reg2, NeweyWest(reg2))
resid2 <- as.numeric(reg2$residuals)
adjusted.values2 <- fitted(reg2)
plot(adjusted.values2, resid2, main="Residual plot Model 2", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)
qqnorm(resid2, col="tomato", main="Quantile-Comparison Plot Model 2")
qqline(resid2, lwd=2, lty=3)
shapiro.test(resid2)
#Regression and residuals values calculations of average size army vs zymotic disease:
cor(data$avg_size_army, data$zymotic)
reg1 <- lm(avg_size_army ~ zymotic, data=data)
coeftest(reg1, NeweyWest(reg1))
#HAC heteroskedasticity autocorrelation robust std errors
#Correlation with Newey-West to have into account the autocorrelation:
#Residuals calculation:
resid1 <- as.numeric(reg1$residuals)
adjusted.values1 <- fitted(reg1)
plot(adjusted.values1, resid1, main="Residual plot Model 1", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)
qqnorm(resid1, col="tomato", main="Quantile-Comparison Plot Model 1")
qqline(resid1, lwd=2, lty=3)
shapiro.test(resid1)
#Regression and residuals values calculations of average size army vs zymotic disease:
cor(data$avg_size_army, data$zymotic)
reg1 <- lm(avg_size_army ~ zymotic, data=data)
coeftest(reg1, NeweyWest(reg1))
#HAC heteroskedasticity autocorrelation robust std errors
#Correlation with Newey-West to have into account the autocorrelation:
#Residuals calculation:
resid1 <- as.numeric(reg1$residuals)
adjusted.values1 <- fitted(reg1)
plot(adjusted.values1, resid1, main="Residual plot Model 1", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)
qqnorm(resid1, col="tomato", main="Quantile-Comparison Plot Model 1")
qqline(resid1, lwd=2, lty=3)
shapiro.test(resid1)
