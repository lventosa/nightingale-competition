---
title: 'Florence Nightingale Competition 2020 - RLadies Spain'
author: "Authors: Laura Ventosa & Esther Manzano"
date: "July 2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---
```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
``` 

*****
# Introduction
*****

- Qui era Florence Nightingale
- De què és la data

*****
# Variables analysis
*****

We check the different types of data on our dataset. The aim is to understand the nature of our variables (i.e. the proportion of numerical and categorical variables) to be able to develope a better model afterwards. Checks on missing values and outliers will be performed in addition.

```{r}
rm(list=ls()) 

#Libraries used across the whole project:     (haurem de revisar quins no fem servir al final i treure'ls)
library(readxl)
library(dplyr)
library(tidyverse)
library(gt)
library(dygraphs)
library(formattable)
library(xts) 
library(lmtest)
library(tseries)
library(sandwich)
library(ResourceSelection)
library(pROC)

#Importing dataset:
data <- read_excel("../nightingale-competition/datos_florence.xlsx", skip=1)
```

## General exploration 

The following table shows the first rows of our dataset, including the names of the variables we have worked with.

```{r}
#Basic information:
head(data)
```
```{r}
#Dimensions of the dataset:
dim(data)
```
```{r}
#Variables:
sapply(data, class)
```
```{r}
summary(data)
```
(Podem afegir aquí una explicació de cada variable, dir què representa, i explicar que després n'afegim més)

## Data treatment (?)

```{r}
#Making everything more readable and column names more manageable:
colnames(data)[1] <- "month"
colnames(data)[2] <- "avg_size_army"
colnames(data)[3] <- "zymotic"
colnames(data)[4] <- "injuries"
colnames(data)[5] <- "other"
colnames(data)[6] <- "zymotic_rate"
colnames(data)[7] <- "injuries_rate"
colnames(data)[8] <- "other_rate"

data[17,1] <- "Aug 1855" #Faig això perquè en el dataset original hi havia escrit Aug_1855
```

As the periods in our dataset are prior to January 1900, R cannot handle them as proper dates. For this reason, we are going to treat time as a numerical variable taking integer value from 0 to 23 in chronological order. This table of equivalences may be useful for the interpretation of the results in this report.

```{r}
#Creating a numeric variable to account for time period:
L <- nrow(data)
time_period <- seq(0,(L-1)) #Podríem passar-ho de 1 a L
data$time_period <- time_period
data <- as.data.frame(data)

#Visualizing in a colorful data table the changes performed:
table_time <- data.frame(
  Month = data$month,
  TimePeriod = data$time_period)

formattable(table_time, list(area(col = Month:TimePeriod) ~ color_tile("lightpink", "lightpink4")))

#He intentat fer una taula una mica més colorida. No he trobar com posar-li títol. Per cert, per fer visualitzacions amb R aquest package que he trobat em sembla super cool, sobretot si les variables són numèriques! hehe Podem jugar amb els colors també.

#time_vars <- select(data, month, time_period)
#time_vars %>% 
  #gt() %>%
    #tab_header(title = md("**Time periods**"), subtitle = md("Equivalence between both variables"))

#He intentat fer-la més maca però el meu coneixement de taules és limitat. Trobo que queda potser una mica estreta però altres dissenys tampoc m'han acabat de fer el pes.
```
```{r}
#Adding new variables to the dataset:
deaths <- vector() 
for(i in 1:L){
  deaths[i] <- data$zymotic[i] + data$injuries[i] + data$other[i]
}
data$total_deaths <- deaths #Agreggated deaths (all causes) per month

cum_deaths <- vector()
cum_deaths <- cumsum(deaths)
data$cum_deaths <- cum_deaths #Cumulative deaths over time
```
EXPLICACIO DE LES NOVES VARIABLES

```{r}
deaths_evol <- select(data, month, total_deaths, time_period)
ordered_deaths <- deaths_evol %>% 
  arrange(desc(deaths_evol$total_deaths)) #Months arranged from higher to lower number of deaths

#Visualizing in a colorful data table the changes performed:
table_deaths <- data.frame(
  Month = ordered_deaths$month,
  TotalDeaths = ordered_deaths$total_deaths,
  TimePeriod = ordered_deaths$time_period)

#A la segona fila per crear el dataframe he canviat accounting(c(3168, 2523, 1970, 1409, 1237, 1042, 939, 859, 763, 672, 594, 582, 549, 485, 382, 243, 199, 137, 92, 50, 43, 21, 17, 6), format = "d") pel que ja hi ha, així queda més net:)

formattable(table_deaths, list(
  Month = color_tile("lightpink", "lightpink4"),
  TotalDeaths = color_bar("grey")))

#He tornat a provar amb aquesta taula hehe, però again sense títol. --> Jo tampoc he pogut jajajaj

#ordered_deaths %>% 
  #gt() %>%
    #tab_header(title = md("**Total deaths by month**"), subtitle = md("Data sorted in descending order"))
#Again, no sé fer la taula més mona jajajaja

#La segona taula m'agrada més d'aquesta manera que l'has feta tu, amb colorins, he modificat els colors per veure com variava però qualsevol joc de colors m'està bé. Per mi la podem deixar així. La primera crec qu elo dels colors queda massa forçat perquè són dues columnes. Podem deixar-la com estava abans o bé mirar de fer-ho d'una altra manera.
```

The above table shows our dataset but sorted by the number of total deaths in descending order. We can observe that
the time period with the highest number of deaths is January 1855, the 10th time period in chronological order. Not surprisingly, April 1854, the first period in our dataset, is the one with the fewest deaths.

## Missing values and outliers

```{r}
#Checking missing values:
colSums(is.na(data)) 
```

As we can see, there are no missing values in our dataset.

```{r}
#Checking outliers:
par(mfrow=c(1,3)) #Amb això es veuen tots tres boxplots alhora ueeee  
boxplot(data$injuries, col="lightgoldenrod", main="Deaths by injuries")
boxplot(data$zymotic, col="mistyrose", main="Deaths by zymotic disease")
boxplot(data$other, col="powderblue", main="Deaths by other causes")
```

Let's recall what we can appreciate in the plots above:
- The majority of deaths by injury are compressed by 0 and 130, approximately. Additionally, there are some exceptional periods where deaths by injury amounted up to 300.
- The majority of deaths by zymotic disease are compressed between 50 and 800 approximately. However, we can see a long tail of cases up to 1700, with some additional outliers of 2100 and 2800.
- The majority of deaths by other alternative causes are compressed between 25 and 75 approximately. We can also appreciate a long tail up to 175 and some outliers of 300 and 350.
To sum up, it seems for now that most of the deaths included in our dataset were caused by zymotic diseases.


*****
# Data vizualization
*****

We are going to explore the dataset in a visual way to see the impacts some variables had on some others:

```{r}
#How did the different type of deaths measured in absolute values evolve in time?
data_plot_1 <- data.frame(
  Time=data$time_period, 
  Zymotic=data$zymotic, 
  Injuries=data$injuries,
  Other=data$other)
dygraph(data_plot_1, main="Death causes (absolute values)")
```

Zymotic disease, with the exception of preriod 17, is the disease that generated more deaths per period. In period 9, the number of deaths for zymotic disease were more than 5 times higher than injuries and other disease.

```{r}
#How did the different type of deaths measured in rate values evolve in time?
data_plot_2 <- data.frame(
  Time=data$time_period,
  Zymotic=data$zymotic_rate, 
  Injuries=data$injuries_rate,
  Other=data$other_rate)
dygraph(data_plot_2, main="Death causes (rates)")
```

The results achieved are very similar than in the graph above.

```{r}
#How did the size of the army evolve in time?
data_plot_4 <- data.frame(
  Time=data$time_period,
  Army=data$avg_size_army)
dygraph(data_plot_4, main="Average size of the army")
```

Despite the high amount in deaths that we could saw in the graphs before, especially in period 9, the size of the army seems not to be that much affected. This can be given by some hidden information that we might not have, such as for example the incorporation of new soldier along the war.

```{r}
#How did the accumulated number of deaths evolve in time?
data_plot_5 <- data.frame(
  Time=data$time_period,
  Accumulated_deaths=cum_deaths) 
dygraph(data_plot_5, main="Accumulated number of deaths")
```

The number of deaths just keeps increasing as long as the war takes place. Especially from periods 9 to 15 we can appreciate an accelerated increase in the accumulated deaths of the army. However, in the last period, we can see a stabilization of sich number, meaning that the war is arriving at its end.

```{r}
# Compute percentages with dplyr
#data <- data  %>%
  #group_by(data$time_period, data$total_deaths) %>%
  #summarise(n = sum(value)) %>%
  #mutate(percentage = n / sum(n)) 
#No em deixa córrer aquesta funció:(

# Plot
#ggplot(data, aes(x=data$time_period, y=percentage, fill=group)) + 
    #geom_area(alpha=0.6 , size=1, colour="black")

# Note: compute percentages without dplyr:
#my_fun <- function(vec){ 
  #as.numeric(vec[2]) / sum(data$value[data$time_period==vec[1]]) *100 
#}
#data$percentage <- apply(data, 1, my_fun)
```


*****
# Regressions
*****

```{r}
#Regression and residuals values calculations of average size army vs zymotic disease:
cor(data$avg_size_army, data$zymotic)  
reg1 <- lm(avg_size_army ~ zymotic, data=data)
summary(reg1)
#Correlation with Newey-West to have into account the autocorrelation
coeftest(reg1, NeweyWest(reg1))

resid1 <- as.numeric(reg1$residuals) #Veig que tu calcules els residus d'una altra manera (comparant-ho amb el bloc de codi on vas fer el QQplot dels residus d'un model). Decidim de quina manera ho deixem
qqnorm(resid1, col="tomato", main="Model 1: Avg Size Army vs. Zymotic")
qqline(resid1, lwd=2, lty=3)
```
```{r}
#Regression and residuals values calculations of average size army vs injuries:
cor(data$avg_size_army, data$injuries)
reg2 <- lm(avg_size_army ~ injuries, data=data)
summary(reg2)
coeftest(reg2, NeweyWest(reg2))

resid2 <- as.numeric(reg2$residuals)
qqnorm(resid2, col="tomato", main="Model 2: Avg Size Army vs. Injuries")
qqline(resid2, lwd=2, lty=3)
```
```{r}
#Regression and residuals values calculations of average size army vs other disease:
cor(data$avg_size_army, data$other)
reg3 <- lm(avg_size_army ~ other, data=data)
summary(reg3)
coeftest(reg3, NeweyWest(reg3))

resid3 <- as.numeric(reg3$residuals)
qqnorm(resid3, col="tomato", main="Model 3: Avg Size Army vs. Other")
qqline(resid3, lwd=2, lty=3)
```
```{r}
#Multivariant linear regresion between all deaths (segregated) and the average size of army:
reg4 <- lm(avg_size_army ~ data$zymotic+data$injuries+data$other, data=data)
summary(reg4)
coeftest(reg4, NeweyWest(reg4))
#Comentem que totes son negatives excepte una. Les morts d'aquesta causa van fer que reclutessin més soldats?

resid4 <- as.numeric(reg4$residuals)
qqnorm(resid4, col="tomato", main="Model 4: Avg Size Army vs. Zymotic, Injuries and Other")
qqline(resid4, lwd=2, lty=3)
```
```{r}
cor(data$avg_size_army, data$total_deaths) #Valor absolut entre 0 i 1? Com més properes a 1 en valor absolut més correlacionades estan.
reg5 <- lm(avg_size_army ~ total_deaths, data=data)
summary(reg5)
coeftest(reg5, NeweyWest(reg5))

resid5 <- as.numeric(reg5$residuals)
qqnorm(resid5, col="tomato", main="Model 5: Avg Size Army vs. Total Deaths")
qqline(resid5, lwd=2, lty=3)
```
```{r}
cor(data$zymotic, data$time_period)
reg6 <- lm(zymotic ~ time_period, data=data)
summary(reg6)
coeftest(reg6, NeweyWest(reg6))

resid6 <- as.numeric(reg6$residuals)
qqnorm(resid6, col="tomato", main="Model 6: Zymotic vs. Time Period")
qqline(resid6, lwd=2, lty=3)
```
```{r}
cor(data$injuries, data$time_period)
reg7 <- lm(injuries ~ time_period, data=data)
summary(reg7)
coeftest(reg7, NeweyWest(reg7))

resid7 <- as.numeric(reg7$residuals)
qqnorm(resid7, col="tomato", main="Model 7: Injuries vs. Time Period")
qqline(resid7, lwd=2, lty=3)
```
```{r}
cor(data$other, data$time_period)
reg8 <- lm(other ~ time_period, data=data)
summary(reg8)
coeftest(reg8, NeweyWest(reg8))

resid8 <- as.numeric(reg8$residuals)
qqnorm(resid8, col="tomato", main="Model 8: Other vs. Time Period")
qqline(resid8, lwd=2, lty=3)
```
```{r}
reg9 <- lm(total_deaths ~ time_period, data=data)
summary(reg9)
coeftest(reg9, NeweyWest(reg9))

resid9 <- as.numeric(reg9$residuals)
qqnorm(resid9, col="tomato", main="Model 9: Total Deaths vs. Time Period")
qqline(resid9, lwd=2, lty=3)
```
```{r}
#Si no fem plot de total_deaths a l'apartat 2 fer-lo aquí juntament amb l'estudi de l'estacionarietat (si no és estacionària no podem aplicar-li un model autoregressiu)
adf.test(data$total_deaths)
# Segons el test és estacionària però tbh mirant el gràfic a mi no m'ho sembla

tra_death <- data.frame(y=data$total_deaths[2:L], lag1=data$total_deaths[1:(L-1)]) 
cor(tra_death$y, tra_death$lag1)
reg10 <- lm(y ~ lag1, data=tra_death)
summary(reg10)
coeftest(reg10, NeweyWest(reg10))

resid10 <- as.numeric(reg10$residuals)
qqnorm(resid10, col="tomato", main="Model 10: Total Deaths vs. Total Deaths Lagged")
qqline(resid10, lwd=2, lty=3)

#Una altra manera de crear models autoregressius:
acf(data$total_deaths, ylim=c(-0.2,1), lwd=5, xlim=c(0,25), col="darkorange2", main="Autocorrelation function total deaths") #Exponential decay
pacf(data$total_deaths, ylim=c(-0.2,1), lwd=5, xlim=c(0,25), col="darkorange2", main="Parcial autocorrelation function total deaths") #Només hi ha un lag que sigui significatiu 
#Pel que ens mostren les funcions d'autocorrelació, el més adequat és un model AR(1)
reg11 <- arima(data$total_deaths, c(1,0,0))
coeftest(reg11)

resid11 <- as.numeric(reg11$residuals)
qqnorm(resid11, col="tomato", main="Model 11: Total Deaths vs. Total Deaths Lagged AR(1)") 
qqline(resid11, lwd=2, lty=3)

#Veiem que tant una regressió lineal calculada amb la funció lm() dóna el mateix model que quan apliquem un model AR(1) aplicant la funció arima()
```

Seasonality: mirar si hi ha algun time period que té mñés significació que alguna altra!
Timeseries o forecast llibreries!

```{r}
# Diagnosi dels models: --> Penso que potser hauriem d'escollir el model que funciona millor/té més correlació i fer-ho sobre aquest!
residual.values <- rstandard(reg1) 
adjusted.values <- fitted(reg1) 
plot(adjusted.values, residual.values, main="Residual plot reg1 (canviar nom maybe)", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)
#He afegit colors al gràfic, poden ser aquests o es poden canviar. Podríem utilitzar els mateixos colors per tots els plots d'un mateix tipus
# Fer diagnosi del model per totes els models i comentar.
```
```{r}
qqnorm(residual.values, col="blue")
qqline(residual.values)

#A la vista del gràfic, no s’observa cap patró especial, de manera que tant la homocedasticitat com la linealitat resulten hipòtesis raonables.
#D’altra banda, el Q_Q plot mostra que les dades no s’ajusten bé a una normal.
```
Queden més amunt o més avall en un costat o en un altre? Com a quin costat és més asimètrica?
Per revisar!

```{r}
reg3 <- lm(formula=data$avg_size_army~data$injuries, data=data) 
summary(reg3)
```


```{r}
#Podem posar-lo abaix si vols a regressions.
data_plot_3 <- data.frame(
  Time=data$time_period,
  Total=data$total_deaths)
dygraph(data_plot_3, main="Total deaths (all causes aggregated)")
#No sé si deixar aquest gràfic aquí o graficar les morts totals a l'apartat 4 mentre expliquem l'estacionarietat de la variable per aplicar un model autoregressiu
```

Provem amb regressions logistiques?


*****
# Predictions
*****

```{r}
#Accuracy de reg1 per fer prediccions (he provat de fer la del número de morts basant-me només en un lag d'aquesta mateixa variable per provar de fer-ne alguna)
train_data <- subset(data, time_period<=round(0.7*L)) #70% training data
test_data <- subset(data, time_period>round(0.7*L)) #30% test/validation data
training1 <- data.frame(y=train_data$total_deaths, lag1=train_data$total_deaths) 
model1 <- lm(y ~ lag1, data=training1)
y.hat1 <- predict(model1, data=test_data)
error1 <- abs(y.hat1 - test_data$total_deaths)
rmse1 <- sqrt((sum(error1)**2)/nrow(test_data)) 
#Fatal performance, tampoc sé si té gaire sentit predir el número de morts futures a partir de les del dia anterior, ens caldria algo amb més chicha
```
```{r}
# Ho hem de fer amb un model que funcioni però... Quina seria la probabilitat de X si Y és això i Z és això altre?
#pred<-predict(reg1, data.frame(Y="1",Z=90),type = "response")
#pred
```
```{r}
# Calculem la bondat de l'ajust: <- s'ha de tocar la data
#hoslem.test(X,fitted(modelX))
```
```{r}
# Dibuixem la corba ROC: <- s'ha de tocar la data
#prob_low=predict(logit_model_2, datA3, type="response")
#r=roc(BW_RE,prob_low, data=datA3)
```

*****
# Conclusions
*****