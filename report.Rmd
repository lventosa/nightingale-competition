---
title: "Florence Nightingale Competition 2020 - RLadies Spain"
author: "Authors: Laura Ventosa and Esther Manzano"
date: "July 2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---
```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
``` 

*****
# Introduction
*****

**Florence Nightingale** (1820-1910), known as *The Lady With the Lamp*, was a British nurse, social reformer and statistician best known as the founder of modern nursing. Her experiences as a nurse during the Crimean War were foundational in her views about sanitation. She established St. Thomas’ Hospital and the Nightingale Training School for Nurses in 1860. Her efforts to reform healthcare greatly influenced the quality of care in the 19 and 20 centuries.

One of her most important discoveries was when she realized that "deaths due to disease were more than seven times the number of deaths due to combat", because of unsanitary hospital conditions. However, as knowing numbers alone have limited persuasive powers, Nightingale used her skills in statistical communication to convince the British parliament of the need to act. She avoided the dry tables used by most statisticians of the time, and instead devised a novel graph to illustrate the impact of hospital and nursing practice reform on army mortality rates.

Moreover, the data presented in the dataset we are going to analyze refer to Florence Nightingale's count of deaths in the Crimean War, which lasted from October 1853 until March 1856. She accounted for the total number of deaths in the Crimean War caused by injuries and combat wounds, zymotic diseases and other causes. Data were grouped by months since April 1854 to March 1856. These data were going to be later used for her rose plots. 


*****
# Data Exploration
*****

We check the different types of data on our dataset. The aim is to understand the nature of our variables (i.e. the proportion of numerical and categorical variables) to be able to develope a better model afterwards. Checks on missing values and outliers will be performed in addition.

```{r}
rm(list=ls()) 

#Libraries used across the whole project:
library(readxl)
library(dplyr)
library(tidyverse)
library(gt)
library(dygraphs)
library(formattable)
library(xts) 
library(lmtest)
library(tseries)
library(sandwich)
library(forecast)
library(ResourceSelection)
library(pROC)
library(reshape2)
```
```{r}
#Importing dataset:
data <- read_excel("../nightingale-competition/datos_florence.xlsx", skip=1)
```

## Basic Information 

The following table shows the first rows of our dataset, including the names of the variables we have worked with.

```{r}
#Basic information:
head(data)
```
```{r}
#Dimensions of the dataset:
dim(data)
```

We can observe that the dimensions of our original dataset are 24x8. That is, 24 rows and 8 columns.

```{r}
#Variables:
sapply(data, class)
```
```{r}
summary(data)
```

Nightingale's original dataset consists of the following variables:

- Month (1): Character variable stating the month and year (period).

- Average size of army (2): Numeric variable that informs the reader about the average size of the army in such period of time.

- Zymotic diseases (3): Numeric variable which states the number of soldiers who died in such period of time for zymotic disease causes in absolute values.

- Wounds & injuries (4): Numeric variable which states the number of soldiers who died in such period of time for wounds and injuries causes in absolute values.

- All other causes (5): Numeric variable which states the number of soldiers who died in such period of time for any other causes in absolute values.

- Zymotic diseases (6): Numeric variable which states the number of soldiers who died in such period of time for zymotic disease causes in rate values.

- Wounds & injuries (7): Numeric variable which states the number of soldiers who died in such period of time for wounds and injuries causes in rate values.

- All other causes (8): Numeric variable which states the number of soldiers who died in such period of time for any other causes in rate values.

In order to make the data more readeable and understandable, we will make some changes in the variables as well as some variable additions.


## Feature Engineering 

```{r}
#Making everything more readable and column names more manageable:
colnames(data)[1] <- "month"
colnames(data)[2] <- "avg_size_army"
colnames(data)[3] <- "zymotic"
colnames(data)[4] <- "injuries"
colnames(data)[5] <- "other"
colnames(data)[6] <- "zymotic_rate"
colnames(data)[7] <- "injuries_rate"
colnames(data)[8] <- "other_rate"

data[17,1] <- "Aug 1855" #We modify this entry as in the original dataset it appeared as Aug_1855.
```

As the periods in our dataset are prior to January 1900, R cannot handle them as proper dates. For this reason, we are going to treat time as a numerical variable taking integer value from 0 to 23 in chronological order. This table of equivalences may be useful for the interpretation of the results in this report.

```{r}
#Creating a numeric variable to account for time period:
L <- nrow(data)
time_period <- seq(0,(L-1)) #Changing from 1 to L
data$time_period <- time_period
data <- as.data.frame(data)

time_vars <- select(data, month, time_period)
time_vars %>% 
  gt() %>%
    tab_header(title = md("**Time periods**"), subtitle = md("Equivalence between both variables"))
```
.
```{r}
#Adding new variables to the dataset:
deaths <- vector() 
for(i in 1:L){
  deaths[i] <- data$zymotic[i] + data$injuries[i] + data$other[i]
}
data$total_deaths <- deaths #Agreggated deaths (all causes) per month

cum_deaths <- vector()
cum_deaths <- cumsum(deaths)
data$cum_deaths <- cum_deaths #Cumulative deaths over time
```

In order to have a better understanding of the data presented, we created a new variable which contains the sum of the different death causes (zymotic, injuries and other) combined. Each entry of this variable will be seggregated by period/month of the year. The name of this new variable is "total_deaths".

In addition, we created another new variable that aims to explain the cumulative deaths over time. Thus, using the new variable of deaths generated just before, we create a new one in order to explain how this aggregated deaths perform over time. The name of this variable is "cum_deaths". 

```{r}
deaths_evol <- select(data, month, total_deaths, time_period)
ordered_deaths <- deaths_evol %>% 
  arrange(desc(deaths_evol$total_deaths)) #Months arranged from higher to lower number of deaths

#Visualizing in a colorful data table the changes performed:
table_deaths <- data.frame(
  Month = ordered_deaths$month,
  TotalDeaths = ordered_deaths$total_deaths,
  TimePeriod = ordered_deaths$time_period)

formattable(table_deaths, list(
  Month = color_tile("lightblue", "lightpink4"),
  TotalDeaths = color_bar("grey")))
```

The above table shows our dataset but sorted by the number of total deaths in descending order. We can observe that
the time period with the highest number of deaths is January 1855, the 10th time period in chronological order. Not surprisingly, April 1854, the first period in our dataset, is the one with the fewest deaths.

## Seasonality Analysis

```{r}
#Abans de comentar les regressions caldria fer l'anàlisi de la seasonality

#Importing dataset:
#data <- read_excel("../nightingale-competition/datos_florence.xlsx", skip=1)

#data('datos_florence.xlsx')
#dat <- datos_florence

#boxplot(data ~ cycle(data))

#plot(data, ylab="Years (1000s)", type="o", pch =20)

#ts (data, frequency = 12, start = c(1854, 4)) # freq 12 => Monthly data. 

#tsData <- data[, 1] # ts data
#decomposedRes <- decompose(tsData, type="additive") # use type = "additive" for additive components
#plot (decomposedRes) # see plot below
#stlRes <- stl(tsData, s.window = "periodic")

```

## Missing Values and Outliers

```{r}
#Checking missing values:
colSums(is.na(data)) 
```

As we can see, there are no missing values in our dataset.

```{r}
#Checking outliers:
par(mfrow=c(1,3)) 
boxplot(data$injuries, col="lightgoldenrod", main="Deaths by injuries")
boxplot(data$zymotic, col="mistyrose", main="Deaths by zymotic disease")
boxplot(data$other, col="powderblue", main="Deaths by other causes")
```

Let's recall what we can appreciate in the plots above:

- The majority of deaths by injury are compressed by 0 and 130, approximately. Additionally, there are some exceptional periods where deaths by injury amounted up to 300.

- The majority of deaths by zymotic disease are compressed between 50 and 800 approximately. However, we can see a long tail of cases up to 1700, with some additional outliers of 2100 and 2800.

- The majority of deaths by other alternative causes are compressed between 25 and 75 approximately. We can also appreciate a long tail up to 175 and some outliers of 300 and 350.

To sum up, it seems for now that most of the deaths included in our dataset were caused by zymotic diseases.

*****
# Data Visualization
*****

We are going to explore the dataset in a visual way to see the impacts some variables had on some others:

```{r}
#How did the different type of deaths measured in absolute values evolve in time?
data_plot_1 <- data.frame(
  Time=data$time_period, 
  Zymotic=data$zymotic, 
  Injuries=data$injuries,
  Other=data$other)
dygraph(data_plot_1, main="Death causes (absolute values)")
```

Zymotic disease, with the exception of preriod 17, is the disease that generated more deaths per period. In period 9, the number of deaths for zymotic disease were more than 5 times higher than injuries and other disease.

```{r}
#How did the different type of deaths measured in rate values evolve in time?
data_plot_2 <- data.frame(
  Time=data$time_period,
  Zymotic=data$zymotic_rate, 
  Injuries=data$injuries_rate,
  Other=data$other_rate)
dygraph(data_plot_2, main="Death causes (rates)")
```

As expected, the results achieved are very similar than in the graph above.

```{r}
#How did the size of the army evolve in time?
data_plot_3 <- data.frame(
  Time=data$time_period,
  Army=data$avg_size_army)
dygraph(data_plot_3, main="Average size of the army")
```

Despite the high amount of deaths that we observed in the graphs above, especially in period 9, the size of the army seems not to be that much affected. This can be caused by some hidden information not captured by the variables given in the dataset, such as for example the incorporation of new soldiers along the war to substitute their dead counterparts.

```{r}
#How did the accumulated number of deaths evolve in time?
data_plot_4 <- data.frame(
  Time=data$time_period,
  Accumulated_deaths=cum_deaths) 
dygraph(data_plot_4, main="Accumulated number of deaths")
```

The number of deaths just keeps increasing as long as the war takes place. Especially from periods 9 to 15 we can appreciate an accelerated increase in the accumulated deaths of the army. However, in the last period, we can see a stabilization of sich number, meaning that the war is arriving at its end.

Let's analyze now the number of deaths by period and disease in absolute values:

```{r}
#We display the data that is more suitable for the graphs:
data=data[1:12,]
data1=data.frame(t(data))
data2=data1[3:5,]
colnames(data2)=month.abb
data2$group=row.names(data2)
data3=melt(data2,id="group")
data3$value=as.numeric(data3$value)
head(data3)
```
```{r}
#Bar graph:
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
        geom_bar(stat="identity")+
        scale_fill_brewer(palette="RdBu")+xlab("")+ylab("")
```
```{r}
#Coordenades polar graph:
ggplot(data=data3,aes(x=variable,y=value,fill=group))+
        geom_bar(stat="identity")+
        coord_polar()+
        scale_fill_brewer(palette="BuPu")+xlab("")+ylab("")
```
```{r}
#Heatmap graph:
ggplot(data=data3,aes(x=variable,y=group,fill=value))+
        geom_tile(colour="black",size=0.1)+
        scale_fill_gradientn(colours=c("white","deepskyblue3"))+
        coord_polar()+xlab("")+ylab("")
```

All three last graph display the same data from different angles. Taking into consideration that the first data we have is from April 1854 and the last one from March 1855, this completes a whole year from different period. Thus, from the data displayed in the graphs, we can identify that the number of deaths experience an exponential increment from April (the war is starting) until October, where it reaches its maximum. From there, is decreases until there is barely any death at the end of March, meaning as well that the war is arriving to an end.

*****
# Regression Analysis
*****

The aim on this section is to show how the variables correlate to each other. Morever, we explore through regressions whether some variables have a significant impact on other variables.

```{r, include = FALSE}
#Regression and residuals values calculations of average size army vs zymotic disease:
cor(data$avg_size_army, data$zymotic)  
reg1 <- lm(avg_size_army ~ zymotic, data=data)
coeftest(reg1, NeweyWest(reg1))

#HAC heteroskedasticity autocorrelation robust std errors
#Correlation with Newey-West to have into account the autocorrelation: 


#Residuals calculation:
resid1 <- as.numeric(reg1$residuals) 
adjusted.values1 <- fitted(reg1) 
plot(adjusted.values1, resid1, main="Residual plot Model 1", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid1, col="tomato", main="Quantile-Comparison Plot Model 1")
qqline(resid1, lwd=2, lty=3)

shapiro.test(resid1)
```

Baixa correlació

```{r, include = FALSE}
#Regression and residuals values calculations of average size army vs injuries:
cor(data$avg_size_army, data$injuries)
reg2 <- lm(avg_size_army ~ injuries, data=data)
summary(reg2)
coeftest(reg2, NeweyWest(reg2))

resid2 <- as.numeric(reg2$residuals) 
adjusted.values2 <- fitted(reg2) 
plot(adjusted.values2, resid2, main="Residual plot Model 2", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid2, col="tomato", main="Quantile-Comparison Plot Model 2")
qqline(resid2, lwd=2, lty=3)

shapiro.test(resid2)
```

Baixa correlació

```{r, include = FALSE}
#Regression and residuals values calculations of average size army vs other disease:
cor(data$avg_size_army, data$other)
reg3 <- lm(avg_size_army ~ other, data=data)
summary(reg3)
coeftest(reg3, NeweyWest(reg3))

resid3 <- as.numeric(reg3$residuals) 
adjusted.values3 <- fitted(reg3) 
plot(adjusted.values3, resid3, main="Residual plot Model 3", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid3, col="tomato", main="Quantile-Comparison Plot Model 3")
qqline(resid3, lwd=2, lty=3)

shapiro.test(resid3)
```

Baixa correlació

```{r, include = FALSE}
#Multivariant linear regresion between all deaths (segregated) and the average size of army:
reg4 <- lm(avg_size_army ~ data$zymotic+data$injuries+data$other, data=data)
summary(reg4)
coeftest(reg4, NeweyWest(reg4))
#Comentem que totes son negatives excepte una. Les morts d'aquesta causa van fer que reclutessin més soldats?

resid4 <- as.numeric(reg4$residuals) 
adjusted.values4 <- fitted(reg4) 
plot(adjusted.values4, resid4, main="Residual plot Model 4", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid4, col="tomato", main="Quantile-Comparison Plot Model 4")
qqline(resid4, lwd=2, lty=3)

shapiro.test(resid4)
```

Baixa correlació en totes

```{r, include = FALSE}
cor(data$avg_size_army, data$total_deaths) #Valor absolut entre 0 i 1? Com més properes a 1 en valor absolut més correlacionades estan.
reg5 <- lm(avg_size_army ~ total_deaths, data=data)
summary(reg5)
coeftest(reg5, NeweyWest(reg5))

resid5 <- as.numeric(reg5$residuals) 
adjusted.values5 <- fitted(reg5) 
plot(adjusted.values5, resid5, main="Residual plot Model 5", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid5, col="tomato", main="Quantile-Comparison Plot Model 5")
qqline(resid5, lwd=2, lty=3)

shapiro.test(resid5)
```

Baixa correlació

```{r, include = FALSE}
cor(data$zymotic, data$time_period)
reg6 <- lm(zymotic ~ time_period, data=data)
summary(reg6)
coeftest(reg6, NeweyWest(reg6))

resid6 <- as.numeric(reg6$residuals) 
adjusted.values6 <- fitted(reg6) 
plot(adjusted.values6, resid6, main="Residual plot Model 6", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid6, col="tomato", main="Quantile-Comparison Plot Model 6")
qqline(resid6, lwd=2, lty=3)

shapiro.test(resid6)
```

Alta correlació

```{r, include = FALSE}
cor(data$injuries, data$time_period)
reg7 <- lm(injuries ~ time_period, data=data)
summary(reg7)
coeftest(reg7, NeweyWest(reg7))

resid7 <- as.numeric(reg7$residuals) 
adjusted.values7 <- fitted(reg7) 
plot(adjusted.values7, resid7, main="Residual plot Model 7", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid7, col="tomato", main="Quantile-Comparison Plot Model 7")
qqline(resid7, lwd=2, lty=3)

shapiro.test(resid7)
```

Baixa correlació

```{r, include = FALSE}
cor(data$other, data$time_period)
reg8 <- lm(other ~ time_period, data=data)
summary(reg8)
coeftest(reg8, NeweyWest(reg8))

resid8 <- as.numeric(reg8$residuals) 
adjusted.values8 <- fitted(reg8) 
plot(adjusted.values8, resid8, main="Residual plot Model 8", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid8, col="tomato", main="Quantile-Comparison Plot Model 8")
qqline(resid8, lwd=2, lty=3)

shapiro.test(resid8)
```

Alta correlació

```{r, include = FALSE}
reg9 <- lm(total_deaths ~ time_period, data=data)
summary(reg9)
coeftest(reg9, NeweyWest(reg9))

resid9 <- as.numeric(reg9$residuals) 
adjusted.values9 <- fitted(reg9) 
plot(adjusted.values9, resid9, main="Residual plot Model 9", ylab="Residual Values", xlab="Adjusted Values", col="lightsalmon3", abline(0, 0), pch=19)

qqnorm(resid9, col="tomato", main="Quantile-Comparison Plot Model 9")
qqline(resid9, lwd=2, lty=3)

shapiro.test(resid9)
```

Alta correlació


```{r}
#For the following model we are interested in total deaths in terms of previous values of the same variable. That is, we want to lag the variable and regress total death on its lags to look for significance. The first step, though, is assess for stationarity of the series.

data_plot_5 <- data.frame(
  Time=data$time_period,
  Total=data$total_deaths)
dygraph(data_plot_5, main="Total deaths (all causes aggregated)")
```
```{r, include = FALSE}
#The series depicted does not seem very stationary. Nonetheless, we counduct a Dickey-Fuller test.
adf.test(data$total_deaths)
#As we cannot reject the null hypotheses of non-stationarity, we will differenciate the data in order to obtain stationarity and be able to run an autoregressive model:

total_deaths_diff <- diff(data$total_deaths)
adf.test(total_deaths_diff)
#By looking at the p-value returned by the test, we can state that the differenced series is not stationary at a 0.05 significance. We differenciate again:

total_deaths_diff2 <- diff(total_deaths_diff)
adf.test(total_deaths_diff2)
#Now that we have finally obtained a stationary series, we can perform an autoregressive model.

acf(total_deaths_diff, ylim=c(-0.2,1), lwd=5, xlim=c(0,15), col="darkorange2", main="Autocorrelation function total deaths") 
pacf(total_deaths_diff, ylim=c(-0.2,1), lwd=5, xlim=c(0,15), col="darkorange2", main="Parcial autocorrelation function total deaths") 

acf(total_deaths_diff2, ylim=c(-0.2,1), lwd=5, xlim=c(0,15), col="darkorange2", main="Autocorrelation function total deaths") 
pacf(total_deaths_diff2, ylim=c(-0.2,1), lwd=5, xlim=c(0,15), col="darkorange2", main="Parcial autocorrelation function total deaths") 

#Drama: amb la data no estacionària no es pot aplicar el model autoregressiu però un cop la diferencio i es converteix en estacionària (total_deaths_diff) o quasi-estacionària (total_death_diff2) no hi ha cap lag (potencials regressors) que semblin ser significatius. Per tant, a la regressió tampoc ho seran --> No afegim aquests dos models? Jo deixaria el raonament aquest explicant why not

tra_death <- data.frame(y=data$total_deaths[2:L], lag1=data$total_deaths[1:(L-1)]) 
cor(tra_death$y, tra_death$lag1)
reg10 <- lm(y ~ lag1, data=tra_death)
summary(reg10)
coeftest(reg10, NeweyWest(reg10))

resid10 <- as.numeric(reg10$residuals)
qqnorm(resid10, col="tomato", main="Model 10: Total Deaths vs. Total Deaths Lagged")
qqline(resid10, lwd=2, lty=3)

#Una altra manera de crear models autoregressius:
reg11 <- arima(data$total_deaths, c(1,0,0))
coeftest(reg11)

resid11 <- as.numeric(reg11$residuals)
qqnorm(resid11, col="tomato", main="Model 11: Total Deaths vs. Total Deaths Lagged AR(1)") 
qqline(resid11, lwd=2, lty=3)

#Veiem que tant una regressió lineal calculada amb la funció lm() dóna el mateix model que quan apliquem un model AR(1) aplicant la funció arima()
```

Revisar si deixar aquesta part:
```{r}
# Diagnosi dels models: --> Penso que potser hauriem d'escollir el model que funciona millor/té més correlació i fer-ho sobre aquest!
residual.values <- rstandard(reg1) 


#He afegit colors al gràfic, poden ser aquests o es poden canviar. Podríem utilitzar els mateixos colors per tots els plots d'un mateix tipus
# Fer diagnosi del model per totes els models i comentar.
```
```{r}
qqnorm(residual.values, col="blue")
qqline(residual.values)

#A la vista del gràfic, no s’observa cap patró especial, de manera que tant la homocedasticitat com la linealitat resulten hipòtesis raonables.
#D’altra banda, el Q_Q plot mostra que les dades no s’ajusten bé a una normal.
```
Queden més amunt o més avall en un costat o en un altre? Com a quin costat és més asimètrica?
Per revisar!

*****
# Predictions
*****

Triar model!

```{r}
#Accuracy de reg1 per fer prediccions (he provat de fer la del número de morts basant-me només en un lag d'aquesta mateixa variable per provar de fer-ne alguna)
train_data <- subset(data, time_period<=round(0.7*L)) #70% training data
test_data <- subset(data, time_period>round(0.7*L)) #30% test/validation data
training1 <- data.frame(y=train_data$total_deaths, lag1=train_data$total_deaths) 
model1 <- lm(y ~ lag1, data=training1)
y.hat1 <- predict(model1, data=test_data) 
error1 <- abs(y.hat1 - test_data$total_deaths)
rmse1 <- sqrt((sum(error1)**2)/nrow(test_data)) 
```
```{r}
# Ho hem de fer amb un model que funcioni però... Quina seria la probabilitat de X si Y és això i Z és això altre?
#pred<-predict(reg1, data.frame(Y="1",Z=90),type = "response")
#pred
```
```{r}
# Calculem la bondat de l'ajust: <- s'ha de tocar la data
#hoslem.test(X,fitted(modelX))
```
```{r}
# Dibuixem la corba ROC: <- s'ha de tocar la data
#prob_low=predict(logit_model_2, datA3, type="response")
#r=roc(BW_RE,prob_low, data=datA3)
```

*****
# Conclusions
*****

*****
# Web References
*****
Useful links to learn more about Florence Nightingale and her legacy:

https://theconversation.com/the-healing-power-of-data-florence-nightingales-true-legacy-134649

https://www.history.com/topics/womens-history/florence-nightingale-1